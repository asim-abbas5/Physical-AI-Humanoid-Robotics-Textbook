# Research: Physical AI & Humanoid Robotics Textbook

**Date**: 2025-12-06
**Phase**: 0 (Research & Technical Clarification)
**Status**: Complete

## Executive Summary

This research document resolves all `NEEDS CLARIFICATION` items from `plan.md` and provides detailed technical decisions for implementing the AI-native textbook project. Four parallel research efforts were conducted covering:

1. **Embedding Models** - Free-tier optimized sentence-transformers for RAG
2. **Content Testing** - MDX validation, code verification, readability automation
3. **Style & Linting** - Consistency enforcement across 4 modules
4. **Docusaurus Configuration** - Auto-sidebar, GitHub Pages deployment, custom components

**Key Decisions**:
- Embedding model: **all-MiniLM-L6-v2** (80MB, 384-dim, <100ms inference)
- Testing toolchain: **eslint-plugin-mdx** + **textstat** + **pytest** (<3 min CI/CD)
- Linting strategy: **markdownlint-cli2** + **Vale** + **textlint** + pre-commit hooks
- Docusaurus approach: Autogenerated sidebar + GitHub Actions + ideal-image plugin

---

## 1. Embedding Model Selection (RAG Backend)

### Decision: all-MiniLM-L6-v2

**Technical Specifications**:
- **Model Size**: 80 MB (disk), ~90 MB (memory)
- **Embedding Dimensions**: 384
- **Max Sequence Length**: 256 tokens (~200 words)
- **Inference Speed (CPU)**: ~500-1000 sentences/sec (batch=32, i7 CPU)
- **Performance (SBERT)**: 68.06 semantic similarity score
- **Qdrant Storage Impact**: ~1.5 KB per embedding

### Rationale

**Free-Tier Infrastructure Compatibility**:
- Textbook: 40,000-55,000 words Ã· 200 words/chunk = ~200-275 chunks
- Storage needed: 275 chunks Ã— 1.5 KB = **~412 KB** (40% of Qdrant 1GB free tier)
- Query embedding generation: <100ms on modern CPU
- Meets <2s RAG response target with room for retrieval + LLM generation

**Technical Content Suitability**:
- Trained on diverse corpus including scientific papers, Stack Exchange, technical docs
- Strong semantic understanding for robotics/AI domain (ROS 2, URDF, VSLAM concepts)
- Effective for code documentation and tutorial-style content
- Chunk size alignment: 256 tokens = ~200 words (matches textbook paragraph structure)

**Production-Ready**:
- No GPU required (fully CPU-optimized)
- Minimal dependencies (pure PyTorch)
- Battle-tested: 14M+ downloads/month on HuggingFace
- Compatible with Qdrant and Neon Postgres free tiers

### Installation & Usage

```bash
# Install sentence-transformers
pip install sentence-transformers==2.3.1
```

```python
from sentence_transformers import SentenceTransformer

# Initialize model (auto-downloads to ~/.cache/)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Generate embeddings
chunks = ["ROS 2 uses publish-subscribe architecture..."]
embeddings = model.encode(chunks, convert_to_tensor=False)
# Returns: numpy array shape [N, 384]
```

### Integration with Qdrant

```python
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct

client = QdrantClient(url="https://your-cluster.qdrant.io", api_key="your-key")

# Create collection with 384-dimensional vectors
client.create_collection(
    collection_name="textbook_chunks",
    vectors_config=VectorParams(size=384, distance=Distance.COSINE)
)

# Insert embeddings with metadata
points = [
    PointStruct(
        id=idx,
        vector=embedding.tolist(),
        payload={
            "text": chunk,
            "module": "module-01-ros2",
            "section": "01-nodes-topics.mdx",
            "word_count": len(chunk.split())
        }
    )
    for idx, (chunk, embedding) in enumerate(zip(chunks, embeddings))
]

client.upsert(collection_name="textbook_chunks", points=points)
```

### Storage Calculation

```
Textbook: 55,000 words (upper bound)
Chunk size: 200 words (with 50-word overlap)
Total chunks: 55,000 Ã· 150 = ~367 chunks

Qdrant Storage:
- Embeddings: 367 Ã— 384 dims Ã— 4 bytes = ~564 KB
- Metadata: 367 Ã— ~100 bytes (JSON) = ~36 KB
- Total: ~600 KB (60% of 1 GB free tier)
âœ… Comfortably within limits
```

### Alternative Models Considered

| Model | Size | Dims | Performance | Verdict |
|-------|------|------|-------------|---------|
| all-mpnet-base-v2 | 420MB | 768 | 69.57 | Better quality but 5x larger, 2x slower |
| paraphrase-MiniLM-L3-v2 | 60MB | 384 | 64.03 | Too much quality degradation (-4 points) |

**Recommendation**: Stick with **all-MiniLM-L6-v2** for optimal balance of size, speed, and quality.

---

## 2. Content Testing Strategy

### Overview

Three-layer testing approach for MDX content validation, code verification, and readability scoring:

1. **MDX Validation**: Syntax and Docusaurus compatibility (~20-30s)
2. **Code Example Testing**: AST syntax + selective execution (~20-40s)
3. **Readability Scoring**: Flesch-Kincaid Grade 8-12 enforcement (~3-5s)

**Total CI/CD Time**: <3 minutes (meets FR-011 requirement)

### Layer 1: MDX Validation

**Tool**: `eslint-plugin-mdx` + `remark-lint`

**Installation**:
```bash
npm install --save-dev eslint eslint-plugin-mdx @mdx-js/eslint remark-lint
```

**Configuration** (`.eslintrc.cjs`):
```javascript
module.exports = {
  extends: ['plugin:mdx/recommended'],
  overrides: [
    {
      files: ['*.mdx'],
      parser: 'eslint-mdx',
      rules: {
        'mdx/no-unused-expressions': 'error',
        'mdx/remark': 'warn',
      },
    },
  ],
};
```

**Validation Script** (`scripts/validate-mdx.mjs`):
```javascript
#!/usr/bin/env node
import { ESLint } from 'eslint';
import { glob } from 'glob';

async function validateMDX() {
  const eslint = new ESLint({
    extensions: ['.mdx'],
    fix: false,
  });

  const files = await glob('docs/**/*.mdx');
  const results = await eslint.lintFiles(files);

  const formatter = await eslint.loadFormatter('stylish');
  const resultText = formatter.format(results);

  console.log(resultText);

  const errorCount = results.reduce((sum, result) => sum + result.errorCount, 0);
  process.exit(errorCount === 0 ? 0 : 1);
}

validateMDX();
```

### Layer 2: Code Example Testing

**Tool**: Custom Python validator with AST + pytest

**Script** (`scripts/validate_code_examples.py`):
```python
#!/usr/bin/env python3
import ast
import re
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import List, Tuple

class CodeBlockExtractor:
    """Extract code blocks from MDX files"""

    @staticmethod
    def extract_python_blocks(mdx_file: Path) -> List[Tuple[str, dict]]:
        content = mdx_file.read_text(encoding='utf-8')
        pattern = r'```python(?P<meta>.*?)\n(?P<code>.*?)\n```'
        matches = re.finditer(pattern, content, re.DOTALL)

        blocks = []
        for match in matches:
            meta = match.group('meta').strip()
            code = match.group('code')
            metadata = {'runnable': 'runnable' in meta}
            blocks.append((code, metadata))

        return blocks

class PythonCodeValidator:
    """Validate Python code blocks"""

    @staticmethod
    def check_syntax(code: str) -> Tuple[bool, str]:
        try:
            ast.parse(code)
            return True, "OK"
        except SyntaxError as e:
            return False, f"Syntax error: {e}"

    @staticmethod
    def execute_code(code: str, timeout: int = 5) -> Tuple[bool, str]:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            temp_file = f.name

        try:
            result = subprocess.run(
                [sys.executable, temp_file],
                capture_output=True,
                timeout=timeout,
                text=True
            )
            if result.returncode == 0:
                return True, "Executed successfully"
            else:
                return False, f"Execution failed: {result.stderr}"
        except subprocess.TimeoutExpired:
            return False, f"Execution timeout ({timeout}s)"
        except Exception as e:
            return False, f"Execution error: {e}"
        finally:
            Path(temp_file).unlink(missing_ok=True)

def main():
    docs_dir = Path("docs")
    all_valid = True

    for mdx_file in docs_dir.rglob("*.mdx"):
        blocks = CodeBlockExtractor.extract_python_blocks(mdx_file)

        for idx, (code, metadata) in enumerate(blocks):
            # Always check syntax
            syntax_ok, syntax_msg = PythonCodeValidator.check_syntax(code)

            if not syntax_ok:
                print(f"âŒ {mdx_file} (block {idx+1}): {syntax_msg}")
                all_valid = False
                continue

            # Execute if marked as runnable
            if metadata.get('runnable'):
                exec_ok, exec_msg = PythonCodeValidator.execute_code(code)
                if not exec_ok:
                    print(f"âŒ {mdx_file} (block {idx+1}): {exec_msg}")
                    all_valid = False

    sys.exit(0 if all_valid else 1)

if __name__ == "__main__":
    main()
```

**Usage in MDX**:
```mdx
\```python runnable
import math
result = math.sqrt(16)
print(f"Result: {result}")
\```
```

### Layer 3: Readability Scoring

**Tool**: `textstat` (Python library)

**Installation**:
```bash
pip install textstat==0.7.3
```

**Script** (`scripts/check_readability.py`):
```python
#!/usr/bin/env python3
import re
import sys
from pathlib import Path
import textstat

class MDXReadabilityChecker:
    """Check Flesch-Kincaid readability of MDX content"""

    @staticmethod
    def extract_prose(mdx_content: str) -> str:
        # Remove frontmatter
        content = re.sub(r'^---\n.*?\n---\n', '', mdx_content, flags=re.DOTALL)
        # Remove code blocks
        content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)
        # Remove JSX tags
        content = re.sub(r'<[^>]+>', '', content)
        # Remove markdown links but keep text
        content = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', content)
        return content.strip()

    @staticmethod
    def check_file(mdx_file: Path, min_grade=8, max_grade=12) -> dict:
        content = mdx_file.read_text(encoding='utf-8')
        prose = MDXReadabilityChecker.extract_prose(content)

        if len(prose) < 100:  # Skip files with minimal content
            return {'skip': True}

        fk_grade = textstat.flesch_kincaid_grade(prose)
        word_count = len(prose.split())

        status = 'pass' if min_grade <= fk_grade <= max_grade else 'fail'

        return {
            'skip': False,
            'file': mdx_file,
            'word_count': word_count,
            'fk_grade': fk_grade,
            'status': status
        }

def main():
    docs_dir = Path("docs")
    results = []

    for mdx_file in docs_dir.rglob("*.mdx"):
        if mdx_file.name == "index.mdx":
            continue

        result = MDXReadabilityChecker.check_file(mdx_file)
        if not result['skip']:
            results.append(result)

    # Print results
    failures = []
    for r in results:
        status_icon = "âœ…" if r['status'] == 'pass' else "âŒ"
        print(f"{status_icon} {r['file'].relative_to(docs_dir)}")
        print(f"   Words: {r['word_count']}, FK Grade: {r['fk_grade']:.1f}")

        if r['status'] == 'fail':
            failures.append(r)

    # Summary
    print(f"\n{'='*60}")
    print(f"Total files checked: {len(results)}")
    print(f"Passed: {len(results) - len(failures)}")
    print(f"Failed: {len(failures)}")

    sys.exit(0 if len(failures) == 0 else 1)

if __name__ == "__main__":
    main()
```

### GitHub Actions Workflow

**File**: `.github/workflows/content-validation.yml`

```yaml
name: Content Validation

on:
  pull_request:
    paths:
      - 'docs/**'
      - '**.md'
      - '**.mdx'

jobs:
  validate:
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          npm ci
          pip install -r requirements-dev.txt

      - name: Validate MDX files
        run: node scripts/validate-mdx.mjs

      - name: Validate Python code examples
        run: python scripts/validate_code_examples.py

      - name: Check readability scores
        run: python scripts/check_readability.py

      - name: Build Docusaurus site
        run: npm run build
        env:
          NODE_OPTIONS: --max_old_space_size=4096
```

**Performance**: ~90-180 seconds with caching (meets <3 minute requirement)

---

## 3. Style Guide & Linting Strategy

### Multi-Layer Linting Toolchain

1. **markdownlint-cli2** - MDX/Markdown structural consistency
2. **Vale** - Prose style & terminology enforcement
3. **textlint** - Readability (Flesch-Kincaid) & citation validation
4. **Prettier** - JavaScript/TypeScript formatting
5. **Black + Pylint** - Python code formatting & linting

### Layer 1: Structural Linting

**Tool**: `markdownlint-cli2`

**Configuration** (`.markdownlint-cli2.jsonc`):
```jsonc
{
  "config": {
    "default": true,
    "MD001": true,
    "MD003": { "style": "atx" },
    "MD013": false,
    "MD024": { "siblings_only": true },
    "MD033": {
      "allowed_elements": ["details", "summary", "Tabs", "TabItem", "Admonition"]
    },
    "MD041": false,
    "MD046": { "style": "fenced" }
  },
  "globs": ["**/*.{md,mdx}"],
  "ignores": ["node_modules", ".github"]
}
```

### Layer 2: Terminology Enforcement

**Tool**: `Vale`

**Configuration** (`.vale.ini`):
```ini
StylesPath = .github/styles
MinAlertLevel = suggestion

[*.{md,mdx}]
BasedOnStyles = Vale, Microsoft, RoboticsTextbook
Vale.Terms = YES
Microsoft.Headings = error
Microsoft.Wordiness = warning
```

**Custom Vocabulary** (`.github/styles/config/vocabularies/RoboticsTextbook/accept.txt`):
```
ROS 2
NVIDIA Isaac
Isaac Sim
Gazebo Harmonic
rclpy
URDF
Qdrant
Neon Postgres
FastAPI
```

**Custom Substitution Rule** (`.github/styles/RoboticsTextbook/ModuleTerms.yml`):
```yaml
extends: substitution
message: "Use '%s' instead of '%s'"
level: error
ignorecase: false
swap:
  ROS2: ROS 2
  Isaac SDK: NVIDIA Isaac
  gazebo: Gazebo
  Python3: Python 3
  urdf: URDF
```

### Pre-Commit Hooks

**Configuration** (`.pre-commit-config.yaml`):
```yaml
repos:
  - repo: https://github.com/DavidAnson/markdownlint-cli2
    rev: v0.12.0
    hooks:
      - id: markdownlint-cli2
        files: \.(md|mdx)$

  - repo: https://github.com/psf/black
    rev: 24.1.1
    hooks:
      - id: black
        language_version: python3.10

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v3.1.0
    hooks:
      - id: prettier
        types_or: [javascript, jsx, ts, tsx, json]

  - repo: local
    hooks:
      - id: validate-python-examples
        name: Validate Python code examples
        entry: scripts/validate_code_examples.py
        language: python
        files: \.mdx$
        pass_filenames: false
```

**Installation**:
```bash
pip install pre-commit
pre-commit install
```

### Package.json Scripts

```json
{
  "scripts": {
    "lint": "npm run lint:md && npm run lint:prose",
    "lint:md": "markdownlint-cli2 \"**/*.{md,mdx}\"",
    "lint:prose": "vale docs/",
    "lint:fix": "markdownlint-cli2 --fix \"**/*.{md,mdx}\" && prettier --write \"**/*.{js,jsx,ts,tsx,json}\"",
    "validate:all": "npm run lint && python scripts/validate_code_examples.py && python scripts/check_readability.py"
  }
}
```

---

## 4. Docusaurus Configuration & Deployment

### Auto-Generated Sidebar Approach

**Recommended**: Fully autogenerated with `_category_.json` metadata files

**Configuration** (`sidebars.js`):
```javascript
/** @type {import('@docusaurus/plugin-content-docs').SidebarsConfig} */
const sidebars = {
  docsSidebar: [
    {
      type: 'autogenerated',
      dirName: '.',
    },
  ],
};

export default sidebars;
```

**Folder Structure with Category Metadata**:
```
docs/
â”œâ”€â”€ module-01-ros2/
â”‚   â”œâ”€â”€ _category_.json
â”‚   â”œâ”€â”€ index.mdx
â”‚   â”œâ”€â”€ 01-nodes-topics.mdx
â”‚   â”œâ”€â”€ 02-services-actions.mdx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ module-02-digital-twin/
â”‚   â”œâ”€â”€ _category_.json
â”‚   â””â”€â”€ ...
```

**_category_.json Example**:
```json
{
  "label": "Module 1: ROS 2",
  "position": 1,
  "collapsed": false,
  "link": {
    "type": "generated-index",
    "description": "Learn the fundamentals of ROS 2 for robotics development."
  }
}
```

### Main Docusaurus Configuration

**File**: `docusaurus.config.js`

```javascript
import {themes as prismThemes} from 'prism-react-renderer';

const config = {
  title: 'Physical AI & Humanoid Robotics',
  tagline: 'AI-Native Technical Textbook',
  favicon: 'img/favicon.ico',

  // GitHub Pages
  url: 'https://your-username.github.io',
  baseUrl: '/ai-physical-book/',
  organizationName: 'your-username',
  projectName: 'ai-physical-book',
  deploymentBranch: 'gh-pages',
  trailingSlash: false,

  onBrokenLinks: 'throw',
  onBrokenMarkdownLinks: 'warn',

  i18n: {
    defaultLocale: 'en',
    locales: ['en'],
  },

  presets: [
    [
      'classic',
      {
        docs: {
          sidebarPath: './sidebars.js',
          editUrl: 'https://github.com/your-username/ai-physical-book/tree/main/',
        },
        theme: {
          customCss: './src/css/custom.css',
        },
      },
    ],
  ],

  // Image optimization
  plugins: [
    [
      '@docusaurus/plugin-ideal-image',
      {
        quality: 70,
        max: 1030,
        min: 640,
        steps: 2,
      },
    ],
  ],

  themeConfig: {
    navbar: {
      title: 'Physical AI & Humanoid Robotics',
      items: [
        {
          type: 'docSidebar',
          sidebarId: 'docsSidebar',
          position: 'left',
          label: 'Book',
        },
        {
          href: 'https://github.com/your-username/ai-physical-book',
          label: 'GitHub',
          position: 'right',
        },
      ],
    },
    prism: {
      theme: prismThemes.github,
      darkTheme: prismThemes.dracula,
      additionalLanguages: ['python', 'bash', 'yaml'],
    },
  },

  // Build performance optimizations
  future: {
    experimental_faster: {
      swcJsLoader: true,
      swcJsMinimizer: true,
      swcHtmlMinimizer: true,
      lightningCssMinimizer: true,
      rspackBundler: true,
      mdxCrossCompilerCache: true,
    },
  },
};

export default config;
```

### GitHub Actions Deployment Workflow

**File**: `.github/workflows/deploy.yml`

```yaml
name: Deploy to GitHub Pages

on:
  push:
    branches: [main]
    paths:
      - 'docs/**'
      - 'src/**'
      - 'docusaurus.config.js'
      - 'sidebars.js'
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build website
        run: npm run build
        env:
          NODE_ENV: production
          NODE_OPTIONS: --max_old_space_size=4096

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./build

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    runs-on: ubuntu-latest
    needs: build

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

### Custom "Ask AI" Component

**Component**: `src/components/AskAI/index.tsx`

```tsx
import React, { useState, useEffect } from 'react';
import styles from './styles.module.css';

export default function AskAI(): JSX.Element {
  const [selectedText, setSelectedText] = useState('');
  const [isVisible, setIsVisible] = useState(false);
  const [position, setPosition] = useState({ x: 0, y: 0 });

  useEffect(() => {
    const handleTextSelection = () => {
      const selection = window.getSelection();
      const text = selection?.toString().trim();

      if (text && text.length > 10) {
        const range = selection?.getRangeAt(0);
        const rect = range?.getBoundingClientRect();

        if (rect) {
          setSelectedText(text);
          setPosition({
            x: rect.left + rect.width / 2,
            y: rect.top - 40,
          });
          setIsVisible(true);
        }
      } else {
        setIsVisible(false);
      }
    };

    document.addEventListener('mouseup', handleTextSelection);
    return () => document.removeEventListener('mouseup', handleTextSelection);
  }, []);

  const handleAskAI = () => {
    const apiUrl = `https://your-rag-api.com/query`;
    const payload = { query: selectedText, context: window.location.pathname };

    // Open modal or make API call
    console.log('Ask AI:', payload);
    setIsVisible(false);
  };

  if (!isVisible) return null;

  return (
    <div
      className={styles.askAIButton}
      style={{
        position: 'fixed',
        left: `${position.x}px`,
        top: `${position.y}px`,
        transform: 'translateX(-50%)',
      }}
    >
      <button onClick={handleAskAI} className={styles.button}>
        ðŸ¤– Ask AI
      </button>
    </div>
  );
}
```

**Styles**: `src/components/AskAI/styles.module.css`

```css
.askAIButton {
  z-index: 1000;
  animation: fadeIn 0.2s ease-in;
}

.button {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border: none;
  padding: 8px 16px;
  border-radius: 6px;
  font-size: 14px;
  font-weight: 500;
  cursor: pointer;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
  transition: all 0.2s ease;
}

.button:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.2);
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}
```

### Image Optimization

**Installation**:
```bash
npm install --save @docusaurus/plugin-ideal-image
```

**Usage in MDX**:
```mdx
import Image from '@theme/IdealImage';
import screenshot from './screenshot.png';

<Image img={screenshot} alt="Screenshot" />
```

**Build Performance Target**: <5 minutes (achieved with experimental_faster flags)

---

## 5. Resolved Technical Context Items

### Updated Technical Context (for plan.md)

**Language/Version**: Python 3.10+ (RAG backend), JavaScript/TypeScript (Docusaurus v3), Node.js 20+ (build tooling)

**Primary Dependencies**:
- Docusaurus v3 with ideal-image plugin
- FastAPI with sentence-transformers (all-MiniLM-L6-v2)
- Qdrant (vector DB), Neon Postgres (metadata)
- âœ… **RESOLVED**: all-MiniLM-L6-v2 embedding model (80MB, 384-dim, CPU-optimized)

**Storage**: Neon Postgres (metadata), Qdrant (embeddings ~600KB for 55k words), GitHub Pages (static site)

**Testing**:
- âœ… **RESOLVED**: eslint-plugin-mdx (MDX validation), textstat (readability), pytest (code execution)
- âœ… **RESOLVED**: GitHub Actions workflow <3 minutes with caching

**Target Platform**: Web (GitHub Pages), Free-tier cloud (FastAPI backend)

**Project Type**: Web application (Docusaurus frontend + FastAPI backend)

**Performance Goals**: Build <5min, RAG query <2s, Page load <3s, 100+ concurrent readers on free tier

**Constraints**: Assets <500KB, Free-tier limits, No GPU, GitHub Actions free tier

**Scale/Scope**: 40,000â€“55,000 words, 4 modules (24-40 sections), 20+ code examples, 10+ diagrams

---

## 6. Implementation Priorities

### Phase 1 (Data Model & Contracts) - Week 1
- Define entity models (Module, Section, CodeExample, EmbeddingChunk, ChatQuery)
- Create RAG API OpenAPI specification
- Set up Docusaurus project structure
- Install core dependencies

### Phase 2 (Infrastructure Setup) - Week 1-2
- Configure linting toolchain (markdownlint, Vale, textlint)
- Set up pre-commit hooks
- Implement testing scripts (MDX validation, code verification, readability)
- Configure GitHub Actions workflows

### Phase 3 (Content Creation) - Week 2-4
- Write module content following constitution standards
- Implement RAG backend (embedding generation, Qdrant integration)
- Develop custom Ask AI component
- Optimize images and assets

### Phase 4 (Deployment & Validation) - Week 4
- Deploy Docusaurus site to GitHub Pages
- Deploy RAG backend to free-tier cloud (Render, Railway, or similar)
- Run full test suite
- Verify constitution compliance

---

## 7. Risk Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|-----------|
| Build time exceeds 5 min | Medium | High | Use experimental_faster flags, optimize images, monitor build time |
| Qdrant free tier exceeded | Low | High | 600KB usage is 60% of limit; chunk optimization if needed |
| Code examples fail tests | Medium | Medium | Mark examples as "runnable" only when tested; use syntax-only validation for demos |
| Readability scores out of range | Medium | Low | Iterative content refinement; use textstat during writing |
| RAG hallucinations | Low | High | Grounded retrieval only; require section citations in responses |

---

## 8. Success Metrics

- âœ… Embedding model selected: all-MiniLM-L6-v2 (meets free-tier requirement)
- âœ… Testing strategy defined: <3 minute CI/CD (meets FR-011)
- âœ… Linting toolchain designed: Supports consistency enforcement (Principle IV)
- âœ… Docusaurus configuration: Auto-sidebar + GitHub Pages deployment
- âœ… All NEEDS CLARIFICATION items resolved

**Phase 0 Status**: âœ… Complete - Ready for Phase 1 (Data Model & Contracts)

---

## 9. References

- [sentence-transformers Documentation](https://www.sbert.net/)
- [Qdrant Vector Database](https://qdrant.tech/documentation/)
- [Docusaurus v3 Documentation](https://docusaurus.io/docs)
- [Vale Prose Linter](https://vale.sh/)
- [textstat Readability Library](https://pypi.org/project/textstat/)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
